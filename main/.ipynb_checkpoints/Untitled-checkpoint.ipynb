{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b36114ea",
   "metadata": {},
   "source": [
    "6 comb\n",
    "\n",
    "* vectorization: \n",
    "    a. bow\n",
    "    b. tfidf\n",
    "    * feature selection\n",
    "        a. chi2\n",
    "        b. f-test\n",
    "        c. mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e17bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import re\n",
    "from data_cleaning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d3548c",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_data = pd.read_csv(\"Train.csv\", sep=',')\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a2808e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating instance and label for Train\n",
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values]\n",
    "X_test_raw = [x[0] for x in test_data[['text']].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0b5c2",
   "metadata": {},
   "source": [
    "#### (1). data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e8b8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. data cleaning (optional)\n",
    "X_train_need_to_clean = pd.DataFrame(X_train_raw)\n",
    "X_test_need_to_clean = pd.DataFrame(X_test_raw)\n",
    "\n",
    "# remove url, # and @\n",
    "X_train_need_to_clean.replace(\"\\b*https?:\\S*\", '', regex=True, inplace=True)\n",
    "X_train_need_to_clean.replace(\"\\b*@\\S*\", '', regex=True, inplace=True)\n",
    "X_train_need_to_clean.replace(\"\\b*#\\S*\", '', regex=True, inplace=True)\n",
    "X_test_need_to_clean.replace(\"\\b*https?:\\S*\", '', regex=True, inplace=True)\n",
    "X_test_need_to_clean.replace(\"\\b*@\\S*\", '', regex=True, inplace=True)\n",
    "X_test_need_to_clean.replace(\"\\b*#\\S*\", '', regex=True, inplace=True)\n",
    "\n",
    "for i in range(X_train_need_to_clean.shape[0]):\n",
    "    X_train_need_to_clean.loc[i, 0] = ' '.join(text_preprocessing(X_train_need_to_clean.loc[i, 0], remove_html=False))\n",
    "\n",
    "X_train_clean = [x[0] for x in X_train_need_to_clean[[0]].values]\n",
    "X_test_clean = [x[0] for x in X_test_need_to_clean[[0]].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505cfc6",
   "metadata": {},
   "source": [
    "#### (2). vectorization (transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e9b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "# countvectorizer\n",
    "BoW_vectorizer = CountVectorizer(analyzer='word', ngram_range=(2,2))\n",
    "X_train_BoW = BoW_vectorizer.fit_transform(X_train_clean)\n",
    "X_test_BoW = BoW_vectorizer.transform(X_test_clean)\n",
    "X_train_tranformed, X_test_transformed = X_train_BoW, X_test_BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abdc991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(2,2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "X_train_tranformed, X_test_transformed = X_train_tfidf, X_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f590369",
   "metadata": {},
   "source": [
    "# 2. feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4469c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2     \n",
    "X_train_new = SelectKBest(chi2,k=5000).fit_transform(X_train_tranformed,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a3e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_classif\n",
    "X_train_new = SelectKBest(f_classif,k=5000).fit_transform(X_train_tranformed,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f944442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutual_info_classif\n",
    "X_train_new = SelectKBest(mutual_info_classif,k=5000).fit_transform(X_train_tranformed,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "843a5ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. split\n",
    "train_size = X_train_tranformed.shape[0]\n",
    "test_size = X_train_tranformed.shape[0]\n",
    "## random hold out\n",
    "ts = test_size/train_size\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_train_new,Y_train, test_size=ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5670eb1c",
   "metadata": {},
   "source": [
    "# 3. modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic: 1152 comb\n",
    "# svm: 4608\n",
    "#rf: 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce0ac1",
   "metadata": {},
   "source": [
    "## base model: 0R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77aa3160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model score:  0.5806348041464086\n"
     ]
    }
   ],
   "source": [
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "basemodel = clf.fit(X_train_raw, Y_train)\n",
    "print(\"base model score: \", basemodel.score(X_train_raw, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71e43103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff26af",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6f1c4",
   "metadata": {},
   "source": [
    "### choose of hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90ef554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "hyper = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'penalty': ['l1', 'l2', 'none', 'elasticnet'],\n",
    "    'C': [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e502ad",
   "metadata": {},
   "source": [
    "##### randomised method (less computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b077e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_logi = RandomizedSearchCV(LogisticRegression(),hyper, scoring='accuracy', cv=5, n_iter=5)\n",
    "logi_result = search_logi.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f6e17e",
   "metadata": {},
   "source": [
    "##### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_logi = GridSearchCV(LogisticRegression(),hyper, scoring='accuracy', cv=5)\n",
    "logi_result = search_logi.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a2344",
   "metadata": {},
   "source": [
    "##### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "157919ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.60447014 0.66808895 0.67528533        nan        nan]\n",
      "  warnings.warn(\n",
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\laizh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(logi_result.cv_results_)\n",
    "logi_result.best_params_\n",
    "logi_result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28babce",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3938f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "print(f\"svm model score: \", svm_model.score(X_test_s,y_test_s))\n",
    "svm_hyper = {\n",
    "    'degree': [3, 5, 10, 15],\n",
    "    'gamma': [1,0.1,0.01,0.001],\n",
    "    'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmod'],\n",
    "    'max_iter': [-1, 100, 500, 1000],\n",
    "    'decision_function_shape': ['ovo', 'ovr']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random method\n",
    "search_svm = RandomizedSearchCV(SVC(), svm_hyper, scoring='accuracy', cv=5, n_iter=100)\n",
    "svm_result = search_svm.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid method\n",
    "search_svm = GridSearchCV(SVC(), svm_hyper, scoring='accuracy', cv=5)\n",
    "svm_result = search_svm.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1218ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_result.cv_results_)\n",
    "svm_result.best_params_\n",
    "svm_result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519020a7",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dffd99d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_hyper = {\n",
    "    'n_estimators': [90, 100, 115 , 130],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(2,20,2),\n",
    "    'min_sample_leaf': range(1,10,1),\n",
    "    'min_samples_split': range(2,10,2),\n",
    "    'max_features': ['auto', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random method\n",
    "search_svm = RandomizedSearchCV(RandomForestClassifier(), rf_hyper, scoring='accuracy', cv=5, n_iter=100)\n",
    "rf_result = search_svm.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid method \n",
    "search_svm = GridSearchCV(RandomForestClassifier(), rf_hyper, scoring='accuracy', cv=5)\n",
    "rf_result = search_svm.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb13d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_result.cv_results_)\n",
    "rf_result.best_params_\n",
    "rf_result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f316425",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(criterion=rf_result.best_params_['criterion'], max_depth=rf_result.best_params_['max_depth'],\n",
    "                                  max_features='log2', min_samples_leaf=rf_result.best_params_['min_sample_leaf'], \n",
    "                                  min_samples_split=rf_result.best_params_['min_samples_split'], n_estimators=rf_result.best_params_['n_estimators'],\n",
    "                                  random_state=0).fit(X_train_s, y_train_s)\n",
    "\n",
    "svm_model = SVC(degree=svm_result.best_params_['degree'], gamma=svm_result.best_params_['gamma'] ,C=svm_result.best_params_['C'], \n",
    "                kernel=svm_result.best_params_['kernel'], max_iter=svm_result.best_params_['max_iter'], \n",
    "                decision_function_shape=svm_result.best_params_['decision_function_shape']).fit(X_train_s, y_train_s)\n",
    "\n",
    "logi_model = LogisticRegression(solver=logi_result.best_params_['solver'], penalty=logi_result.best_params_['penalty'],\n",
    "                                C=logi_result.best_params_['C'], max_iter=logi_result.best_params_['max_iter'],\n",
    "                                multi_class=logi_result.best_params_['multi_class']).fit(X_train_s, y_train_s)\n",
    "\n",
    "estimators = [('rf', rf_model),('svr', svm_model), ('log', logi_model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_stacking = StackingClassifier(estimator=estimators, final_estimator=DecisionTreeClassifier()).fit(X_train_s, y_train_s)\n",
    "dt_stacking.score(X_test_s, y_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d24ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_stacking = StackingClassifier(estimator=estimators, final_estimator=SVC()).fit(X_train_s, y_train_s)\n",
    "dt.stacking.score(X_test_s, y_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9440ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=200)).fit(X_train_s, y_train_s)\n",
    "dt.stacking.score(X_test_s, y_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81678286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e355a709",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dea8ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
