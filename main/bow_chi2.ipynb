{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b4f3b9",
   "metadata": {},
   "source": [
    "6 comb\n",
    "\n",
    "* vectorization: \n",
    "    a. bow\n",
    "    b. tfidf\n",
    "    * feature selection\n",
    "        a. chi2\n",
    "        b. f-test\n",
    "        c. mi\n",
    "        models:\n",
    "            # logistic: 1008 comb\n",
    "            # svm: 2688\n",
    "            # rf: 8000\n",
    "            \n",
    "            \n",
    "total: 82560 combs\n",
    "lots of 5 cross validation = g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7dc56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import re\n",
    "from data_cleaning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e185d1",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1da73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_data = pd.read_csv(\"Train.csv\", sep=',')\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a2808e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating instance and label for Train\n",
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values]\n",
    "X_test_raw = [x[0] for x in test_data[['text']].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0b5c2",
   "metadata": {},
   "source": [
    "#### (1). data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8b8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. data cleaning (optional)\n",
    "X_train_need_to_clean = pd.DataFrame(X_train_raw)\n",
    "X_test_need_to_clean = pd.DataFrame(X_test_raw)\n",
    "\n",
    "# remove url, # and @\n",
    "X_train_need_to_clean.replace(\"\\b*https?:\\S*\", '', regex=True, inplace=True)\n",
    "X_train_need_to_clean.replace(\"\\b*@\\S*\", '', regex=True, inplace=True)\n",
    "X_train_need_to_clean.replace(\"\\b*#\\S*\", '', regex=True, inplace=True)\n",
    "X_test_need_to_clean.replace(\"\\b*https?:\\S*\", '', regex=True, inplace=True)\n",
    "X_test_need_to_clean.replace(\"\\b*@\\S*\", '', regex=True, inplace=True)\n",
    "X_test_need_to_clean.replace(\"\\b*#\\S*\", '', regex=True, inplace=True)\n",
    "\n",
    "for i in range(X_train_need_to_clean.shape[0]):\n",
    "    X_train_need_to_clean.loc[i, 0] = ' '.join(text_preprocessing(X_train_need_to_clean.loc[i, 0], remove_html=False))\n",
    "\n",
    "for i in range(X_test_need_to_clean.shape[0]):\n",
    "    X_test_need_to_clean.loc[i, 0] = ' '.join(text_preprocessing(X_test_need_to_clean.loc[i, 0], remove_html=False))    \n",
    "\n",
    "X_train_need_to_clean.replace('[^\\w\\s]','', regex=True, inplace=True)\n",
    "X_test_need_to_clean.replace('[^\\w\\s]','', regex=True, inplace=True)\n",
    "    \n",
    "    \n",
    "X_train_clean = [x[0] for x in X_train_need_to_clean[[0]].values]\n",
    "X_test_clean = [x[0] for x in X_test_need_to_clean[[0]].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d505cfc6",
   "metadata": {},
   "source": [
    "#### (2). vectorization (transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "# countvectorizer\n",
    "BoW_vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "X_train_BoW = BoW_vectorizer.fit_transform(X_train_clean)\n",
    "X_test_BoW = BoW_vectorizer.transform(X_test_clean)\n",
    "\n",
    "X_train_tranformed, X_test_transformed = X_train_BoW, X_test_BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728224a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_clean)\n",
    "\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "X_train_tranformed, X_test_transformed = X_train_tfidf, X_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00eb209",
   "metadata": {},
   "source": [
    "### comparison between data with preprocessing and without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efa9e23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21802, 204657)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CountVectorizer(analyzer='word', ngram_range=(2,2)).fit_transform(X_train_raw).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0ba93d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21802, 127482)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tranformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df12cbb",
   "metadata": {},
   "source": [
    "# 2. feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8caae81",
   "metadata": {},
   "source": [
    "### type of selector (choose one of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4469c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2     \n",
    "selector = SelectKBest(chi2,k=10000)\n",
    "X_train_new = selector.fit_transform(X_train_tranformed,Y_train)\n",
    "X_test_new = selector.transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9216c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_classifs\n",
    "selector = SelectKBest(f_classif,k=5000)\n",
    "X_train_new = selector.fit_transform(X_train_tranformed,Y_train)\n",
    "X_test_new = selector.transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eb66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutual_info_classif\n",
    "selector = SelectKBest(mutual_info_classif,k=10000)\n",
    "X_train_new = selector.fit_transform(X_train_tranformed,Y_train)\n",
    "X_test_new = selector.transform(X_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5670eb1c",
   "metadata": {},
   "source": [
    "# 3. training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a51c48",
   "metadata": {},
   "source": [
    "### split data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dbc072",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = X_train_tranformed.shape[0]\n",
    "test_size = X_test_transformed.shape[0]\n",
    "## random hold out\n",
    "ts = test_size/train_size\n",
    "X_train_s, X_validation, y_train_s, y_validation = train_test_split(X_train_new,Y_train, test_size=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b58f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = round(X_train_s.shape[0] / X_validation.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd4222",
   "metadata": {},
   "source": [
    "#### Prototype selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc1960fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train_s, y_train_s)\n",
    "X_train_s, y_train_s = X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fa56ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    2668\n",
       "neutral     2668\n",
       "positive    2668\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_labels = pd.DataFrame(y_resampled)\n",
    "resampled_labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2b7691",
   "metadata": {},
   "source": [
    "#### Prototype generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b727ef5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16532/3286263636.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClusterCentroids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClusterCentroids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_train_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_generation\\_cluster_centroids.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampling_strategy_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtarget_class\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"n_clusters\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_class_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m                 X_new, y_new = self._generate_sample(\n\u001b[0;32m    192\u001b[0m                     \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_class_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[1;31m# run a k-means once\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             labels, inertia, centers, n_iter_ = kmeans_single(\n\u001b[0m\u001b[0;32m   1187\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36m_kmeans_single_elkan\u001b[1;34m(X, sample_weight, centers_init, max_iter, verbose, x_squared_norms, tol, n_threads)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;31m# center of each center for next iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[0mcenter_half_distances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenters_new\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         distance_next_center = np.partition(\n\u001b[0m\u001b[0;32m    493\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenter_half_distances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m         )[1]\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpartition\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=0)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train_s, y_train_s)\n",
    "X_train_s, y_train_s = X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d76f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_labels = pd.DataFrame(y_resampled)\n",
    "resampled_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = round(X_train_s.shape[0] / X_validation.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce0ac1",
   "metadata": {},
   "source": [
    "## base model: 0R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DummyClassifier(strategy='most_frequent')\n",
    "basemodel = clf.fit(X_train_raw, Y_train)\n",
    "print(\"base model score: \", basemodel.score(X_train_raw, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff26af",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6f1c4",
   "metadata": {},
   "source": [
    "### choose of hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "hyper = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'penalty': ['l1', 'l2', 'none', 'elasticnet'],\n",
    "    'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e502ad",
   "metadata": {},
   "source": [
    "##### randomised method (less computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077e4fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_logi = RandomizedSearchCV(LogisticRegression(),hyper, scoring='accuracy', cv=cv, n_iter=101)\n",
    "logi_result = search_logi.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f6e17e",
   "metadata": {},
   "source": [
    "##### grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5d0ef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_logi = GridSearchCV(LogisticRegression(),hyper, scoring='accuracy', cv=cv)\n",
    "logi_result = search_logi.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a2344",
   "metadata": {},
   "source": [
    "##### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157919ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(logi_result.cv_results_)\n",
    "print(logi_result.best_params_)\n",
    "print(logi_result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28babce",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3938f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_hyper = {\n",
    "    'degree': [3, 5, 10, 15],\n",
    "    'gamma': [1,0.1,0.01,0.001],\n",
    "    'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmod'],\n",
    "    'max_iter': [100, 500, 1000],\n",
    "    'decision_function_shape': ['ovo', 'ovr']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random method\n",
    "search_svm = RandomizedSearchCV(SVC(), svm_hyper, scoring='accuracy', cv=cv, n_iter=269)\n",
    "svm_result = search_svm.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f9ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid method\n",
    "search_svm = GridSearchCV(SVC(), svm_hyper, scoring='accuracy', cv=cv)\n",
    "svm_result = search_svm.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1218ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(svm_result.cv_results_)\n",
    "print(svm_result.best_params_)\n",
    "print(svm_result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519020a7",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd99d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_hyper = {\n",
    "    'n_estimators': [90, 100, 115 , 130],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(2,20,2),\n",
    "    'min_samples_leaf': range(1,10,1),\n",
    "    'min_samples_split': range(2,10,2),\n",
    "    'max_features': ['auto', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b1e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random method\n",
    "search_svm = RandomizedSearchCV(RandomForestClassifier(), rf_hyper, scoring='accuracy', cv=cv, n_iter=800)\n",
    "rf_result = search_svm.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid method \n",
    "search_svm = GridSearchCV(RandomForestClassifier(), rf_hyper, scoring='accuracy', cv=cv)\n",
    "rf_result = search_svm.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb13d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_result.cv_results_)\n",
    "print(rf_result.best_params_)\n",
    "print(rf_result.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f316425",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3740c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(criterion=rf_result.best_params_['criterion'], max_depth=rf_result.best_params_['max_depth'],\n",
    "                                  max_features='log2', min_samples_leaf=rf_result.best_params_['min_samples_leaf'], \n",
    "                                  min_samples_split=rf_result.best_params_['min_samples_split'], n_estimators=rf_result.best_params_['n_estimators'],\n",
    "                                  random_state=0).fit(X_train_s, y_train_s)\n",
    "\n",
    "svm_model = SVC(degree=svm_result.best_params_['degree'], gamma=svm_result.best_params_['gamma'] ,C=svm_result.best_params_['C'], \n",
    "                kernel=svm_result.best_params_['kernel'], max_iter=svm_result.best_params_['max_iter'], \n",
    "                decision_function_shape=svm_result.best_params_['decision_function_shape']).fit(X_train_s, y_train_s)\n",
    "\n",
    "logi_model = LogisticRegression(solver=logi_result.best_params_['solver'], penalty=logi_result.best_params_['penalty'],\n",
    "                                C=logi_result.best_params_['C'], max_iter=logi_result.best_params_['max_iter'],\n",
    "                                multi_class=logi_result.best_params_['multi_class']).fit(X_train_s, y_train_s)\n",
    "\n",
    "estimators = [('rf', rf_model),('svr', svm_model), ('log', logi_model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c2e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_stacking = StackingClassifier(estimators=estimators, final_estimator=DecisionTreeClassifier()).fit(X_train_s, y_train_s)\n",
    "dt_stacking.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d24ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_stacking = StackingClassifier(estimators=estimators, final_estimator=SVC()).fit(X_train_s, y_train_s)\n",
    "svm_stacking.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9440ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logi_stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=200)).fit(X_train_s, y_train_s)\n",
    "logi_stacking.score(X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e355a709",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17893cbe",
   "metadata": {},
   "source": [
    "### score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8fd5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c84f5c",
   "metadata": {},
   "source": [
    "#### 0R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e9084",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cdca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0266e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv =round(X_train_s.shape[0]/X_validation.shape[0])\n",
    "cv = 5\n",
    "\n",
    "\n",
    "# basestic\n",
    "print(\"basemodel: 0R\")\n",
    "\n",
    "# validation acc\n",
    "vc = np.mean(cross_val_score(basemodel,X_validation, y_validation, cv=cv))\n",
    "print(\"Validation accuracy: \", vc)\n",
    "\n",
    "# predictions for test data\n",
    "base_label = basemodel.predict(X_test_new)\n",
    "\n",
    "base_validation_label = basemodel.predict(X_validation)\n",
    "\n",
    "# macro metrics\n",
    "base_precision_m = precision_score(y_validation,base_validation_label, average = 'macro')\n",
    "print('macro precision is ', base_precision_m)\n",
    "\n",
    "base_recall_m = recall_score(y_validation,base_validation_label, average = 'macro')\n",
    "print('macro recall is ', base_recall_m)\n",
    "\n",
    "# f1\n",
    "base_f1_m = f1_score(y_validation,base_validation_label, average = 'macro')\n",
    "print('macro f1 is ', base_f1_m)\n",
    "\n",
    "\n",
    "# weighted metrics\n",
    "base_precision_w = precision_score(y_validation,base_validation_label, average = 'weighted')\n",
    "print('weighted precision is ', base_precision_w)\n",
    "\n",
    "base_recall_w = recall_score(y_validation,base_validation_label, average = 'weighted')\n",
    "print('weighted recall is ', base_recall_w)\n",
    "\n",
    "# f1\n",
    "base_f1_w = f1_score(y_validation,base_validation_label, average = 'weighted')\n",
    "print('weighted f1 is ', base_f1_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a6b00",
   "metadata": {},
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic\n",
    "print(\"Logistic Regression\")\n",
    "\n",
    "# validation acc\n",
    "vc = np.mean(cross_val_score(logi_model,X_validation, y_validation, cv=cv))\n",
    "print(\"Validation accuracy: \", vc)\n",
    "\n",
    "# predictions for test data\n",
    "logi_label = logi_model.predict(X_test_new)\n",
    "\n",
    "logi_validation_label = logi_model.predict(X_validation)\n",
    "\n",
    "# macro metrics\n",
    "logi_precision_m = precision_score(y_validation,logi_validation_label, average = 'macro')\n",
    "print('macro precision is ', logi_precision_m)\n",
    "\n",
    "logi_recall_m = recall_score(y_validation,logi_validation_label, average = 'macro')\n",
    "print('macro recall is ', logi_recall_m)\n",
    "\n",
    "# f1\n",
    "logi_f1_m = f1_score(y_validation,logi_validation_label, average = 'macro')\n",
    "print('macro f1 is ', logi_f1_m)\n",
    "\n",
    "\n",
    "# weighted metrics\n",
    "logi_precision_w = precision_score(y_validation,logi_validation_label, average = 'weighted')\n",
    "print('weighted precision is ', logi_precision_w)\n",
    "\n",
    "logi_recall_w = recall_score(y_validation,logi_validation_label, average = 'weighted')\n",
    "print('weighted recall is ', logi_recall_w)\n",
    "\n",
    "# f1\n",
    "logi_f1_w = f1_score(y_validation,logi_validation_label, average = 'weighted')\n",
    "print('weighted f1 is ', logi_f1_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5296f59",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm\n",
    "print(\"SVM\")\n",
    "\n",
    "# validation acc\n",
    "vc = np.mean(cross_val_score(svm_model,X_validation, y_validation, cv=cv))\n",
    "print(\"Validation accuracy: \", vc)\n",
    "\n",
    "# predictions for test data\n",
    "svm_label = svm_model.predict(X_test_new)\n",
    "\n",
    "svm_validation_label = svm_model.predict(X_validation)\n",
    "\n",
    "# macro metrics\n",
    "svm_precision_m = precision_score(y_validation,svm_validation_label, average = 'macro')\n",
    "print('macro precision is ', svm_precision_m)\n",
    "\n",
    "svm_recall_m = recall_score(y_validation,svm_validation_label, average = 'macro')\n",
    "print('macro recall is ', svm_recall_m)\n",
    "\n",
    "# f1\n",
    "svm_f1_m = f1_score(y_validation,svm_validation_label, average = 'macro')\n",
    "print('macro f1 is ', svm_f1_m)\n",
    "\n",
    "\n",
    "# weighted metrics\n",
    "svm_precision_w = precision_score(y_validation,svm_validation_label, average = 'weighted')\n",
    "print('weighted precision is ', svm_precision_w)\n",
    "\n",
    "svm_recall_w = recall_score(y_validation,svm_validation_label, average = 'weighted')\n",
    "print('weighted recall is ', svm_recall_w)\n",
    "\n",
    "# f1\n",
    "svm_f1_w = f1_score(y_validation,svm_validation_label, average = 'weighted')\n",
    "print('weighted f1 is ', svm_f1_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157e701",
   "metadata": {},
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70b7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "print(\"random forest\")\n",
    "\n",
    "# validation acc\n",
    "vc = np.mean(cross_val_score(rf_model,X_validation, y_validation, cv=cv))\n",
    "print(\"Validation accuracy: \", vc)\n",
    "\n",
    "# predictions for test data\n",
    "rf_label = rf_model.predict(X_test_new)\n",
    "\n",
    "rf_validation_label = rf_model.predict(X_validation)\n",
    "\n",
    "# macro metrics\n",
    "rf_precision_m = precision_score(y_validation,rf_validation_label, average = 'macro')\n",
    "print('macro precision is ', rf_precision_m)\n",
    "\n",
    "rf_recall_m = recall_score(y_validation,rf_validation_label, average = 'macro')\n",
    "print('macro recall is ', rf_recall_m)\n",
    "\n",
    "# f1\n",
    "rf_f1_m = f1_score(y_validation,rf_validation_label, average = 'macro')\n",
    "print('macro f1 is ', rf_f1_m)\n",
    "\n",
    "\n",
    "# weighted metrics\n",
    "rf_precision_w = precision_score(y_validation,rf_validation_label, average = 'weighted')\n",
    "print('weighted precision is ', rf_precision_w)\n",
    "\n",
    "rf_recall_w = recall_score(y_validation,rf_validation_label, average = 'weighted')\n",
    "print('weighted recall is ', rf_recall_w)\n",
    "\n",
    "# f1\n",
    "rf_f1_w = f1_score(y_validation,rf_validation_label, average = 'weighted')\n",
    "print('weighted f1 is ', rf_f1_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a62a7c",
   "metadata": {},
   "source": [
    "#### stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5cc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_stacking\n",
    "print(\"svm_stacking\")\n",
    "\n",
    "# validation acc\n",
    "vc = np.mean(cross_val_score(svm_stacking,X_validation, y_validation, cv=cv))\n",
    "print(\"Validation accuracy: \", vc)\n",
    "\n",
    "# predictions for test data\n",
    "ss_label = svm_stacking.predict(X_test_new)\n",
    "\n",
    "ss_validation_label = svm_stacking.predict(X_validation)\n",
    "\n",
    "# macro metrics\n",
    "ss_precision_m = precision_score(y_validation,ss_validation_label, average = 'macro')\n",
    "print('macro precision is ', ss_precision_m)\n",
    "\n",
    "ss_recall_m = recall_score(y_validation,ss_validation_label, average = 'macro')\n",
    "print('macro recall is ', ss_recall_m)\n",
    "\n",
    "# f1\n",
    "ss_f1_m = f1_score(y_validation,ss_validation_label, average = 'macro')\n",
    "print('macro f1 is ', ss_f1_m)\n",
    "\n",
    "\n",
    "# weighted metrics\n",
    "ss_precision_w = precision_score(y_validation,ss_validation_label, average = 'weighted')\n",
    "print('weighted precision is ', ss_precision_w)\n",
    "\n",
    "ss_recall_w = recall_score(y_validation,ss_validation_label, average = 'weighted')\n",
    "print('weighted recall is ', ss_recall_w)\n",
    "\n",
    "# f1\n",
    "ss_f1_w = f1_score(y_validation,ss_validation_label, average = 'weighted')\n",
    "print('weighted f1 is ', ss_f1_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b29235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dt_stacking\n",
    "print(\"dt_stacking\")\n",
    "\n",
    "# validation acc\n",
    "vc = np.mean(cross_val_score(dt_stacking,X_validation, y_validation, cv=cv))\n",
    "print(\"Validation accuracy: \", vc)\n",
    "\n",
    "# predictions for test data\n",
    "dts_label = dt_stacking.predict(X_test_new)\n",
    "\n",
    "dts_validation_label = dt_stacking.predict(X_validation)\n",
    "\n",
    "# macro metrics\n",
    "dts_precision_m = precision_score(y_validation,dts_validation_label, average = 'macro')\n",
    "print('macro precision is ', dts_precision_m)\n",
    "\n",
    "dts_recall_m = recall_score(y_validation,dts_validation_label, average = 'macro')\n",
    "print('macro recall is ', dts_recall_m)\n",
    "\n",
    "# f1\n",
    "dts_f1_m = f1_score(y_validation,dts_validation_label, average = 'macro')\n",
    "print('macro f1 is ', dts_f1_m)\n",
    "\n",
    "\n",
    "# weighted metrics\n",
    "dts_precision_w = precision_score(y_validation,dts_validation_label, average = 'weighted')\n",
    "print('weighted precision is ', dts_precision_w)\n",
    "\n",
    "dts_recall_w = recall_score(y_validation,dts_validation_label, average = 'weighted')\n",
    "print('weighted recall is ', dts_recall_w)\n",
    "\n",
    "# f1\n",
    "dts_f1_w = f1_score(y_validation,dts_validation_label, average = 'weighted')\n",
    "print('weighted f1 is ', dts_f1_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa7371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# logi_stacking\n",
    "print(\"logi_stacking\")\n",
    "\n",
    "# validation acc\n",
    "vc = np.mean(cross_val_score(logi_stacking,X_validation, y_validation, cv=cv))\n",
    "print(\"Validation accuracy: \", vc)\n",
    "\n",
    "# predictions for test data\n",
    "logi_s_label = logi_stacking.predict(X_test_new)\n",
    "\n",
    "logi_s_validation_label = logi_stacking.predict(X_validation)\n",
    "\n",
    "# macro metrics\n",
    "logi_s_precision_m = precision_score(y_validation,logi_s_validation_label, average = 'macro')\n",
    "print('macro precision is ', logi_s_precision_m)\n",
    "\n",
    "logi_s_recall_m = recall_score(y_validation,logi_s_validation_label, average = 'macro')\n",
    "print('macro recall is ', logi_s_recall_m)\n",
    "\n",
    "# f1\n",
    "logi_s_f1_m = f1_score(y_validation,logi_s_validation_label, average = 'macro')\n",
    "print('macro f1 is ', logi_s_f1_m)\n",
    "\n",
    "\n",
    "# weighted metrics\n",
    "logi_s_precision_w = precision_score(y_validation,logi_s_validation_label, average = 'weighted')\n",
    "print('weighted precision is ', logi_s_precision_w)\n",
    "\n",
    "logi_s_recall_w = recall_score(y_validation,logi_s_validation_label, average = 'weighted')\n",
    "print('weighted recall is ', logi_s_recall_w)\n",
    "\n",
    "# f1\n",
    "logi_s_f1_w = f1_score(y_validation,logi_s_validation_label, average = 'weighted')\n",
    "print('weighted f1 is ', logi_s_f1_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d208a42",
   "metadata": {},
   "source": [
    "# 5. Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f23361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "plot_confusion_matrix(logi_model, X_validation, y_validation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd921f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm\n",
    "plot_confusion_matrix(svm_model, X_validation, y_validation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "plot_confusion_matrix(rf_model, X_validation, y_validation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58de3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_stacking\n",
    "plot_confusion_matrix(svm_stacking, X_validation, y_validation)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a91eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_stacking\n",
    "plot_confusion_matrix(dt_stacking, X_validation, y_validation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b993faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logi_stacking\n",
    "plot_confusion_matrix(logi_stacking, X_validation, y_validation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e31db14",
   "metadata": {},
   "source": [
    "## output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efc4cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "prediction_label = ss_label\n",
    "with open('prediction.csv','w') as output:\n",
    "    output.write(\"id,sentiment\\n\")\n",
    "    for i in range(0,len(prediction_label)):\n",
    "        output.write(str(test_data['id'].iloc[i]))\n",
    "        output.write(\",\")\n",
    "        output.write(prediction_label[i])\n",
    "        output.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3763faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7971"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a708f493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8079x5000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11927 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e09044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
